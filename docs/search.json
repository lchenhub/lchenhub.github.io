[
  {
    "objectID": "Blog.html",
    "href": "Blog.html",
    "title": "Blog & Portfolio",
    "section": "",
    "text": "Exercise\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nImpact of Poverty on a City’s Overall Readiness for Climate Adaptation\n\n\n\nMEDS\n\n\nStatistics\n\n\nPoverty\n\n\nClimate Adaptation\n\n\nR\n\n\n\n\n\n\n\nLiane Chen\n\n\nDec 15, 2023\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nHistorical Redlining and Bird Sampling Disparity\n\n\n\nMEDS\n\n\nRedlining\n\n\nBirds\n\n\nEnvironmental Justice\n\n\n\nAnalysis of historical redlining data as it relates to geographical disparities in bird biodiversity sampling in the United States\n\n\n\nLiane Chen\n\n\nDec 14, 2023\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAQI Analysis in Santa Barbara\n\n\n\nMEDS\n\n\nAir Quality\n\n\nWildfire\n\n\n\nTime series analysis for Air Quality Index(AQI) before, during, and after Thomas Fire\n\n\n\nLiane Chen\n\n\nDec 13, 2023\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nEthics and Bias in Environmental Data Science\n\n\n\nMEDS\n\n\nEthics\n\n\nAI\n\n\nClimate Adaptation\n\n\nEnergy\n\n\n\nAI and Climate Change Solutions\n\n\n\nLiane Chen\n\n\nDec 11, 2023\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nLiane’s first blog post\n\n\n\nQuarto\n\n\nMEDS\n\n\nWorkshop\n\n\n\nHere is where the final blog posts will live\n\n\n\nLiane Chen\n\n\nOct 23, 2023\n\n\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "blog/2023-12-13-thomas-fire/AQI_falsecolor.html",
    "href": "blog/2023-12-13-thomas-fire/AQI_falsecolor.html",
    "title": "AQI Analysis in Santa Barbara",
    "section": "",
    "text": "Author: Liane Chen\nGitHub link: https://github.com/lchenhub/eds220-hwk4-task3.git\n\n\n\n\nIn this notebook, we use Air Quality Index (AQI) data from the US Environmental Protection Agency to visualize the impact on the AQI of the 2017 Thomas Fire in Santa Barbara County. We also will create a false color image showing the fire scar of the Thomas fire in 2017.\n\n\n\n\nFetch vector data from an online repository\nData wrangling and exploration of with pandas\nGeospatial data wrangling with geopandas\nCreating and customizing a line plot\nCreating and customizing a false color image\n\n\n\n\nIn this notebook we use three datasets:\n\nAir Quality Index (AQI) data from the US Environmental Protection Agency\n\nThe first dataset contains information about EPA’s index for reporting air quality.\nFor each pollutant an AQI value of 100 generally corresponds to an ambient air concentration that equals the level of the short-term national ambient air quality standard for protection of public health. AQI values at or below 100 are generally thought of as satisfactory. When AQI values are above 100, air quality is unhealthy: at first for certain sensitive groups of people, then for everyone as AQI values get higher.\nThe AQI is divided into six categories. Each category corresponds to a different level of health concern.\n\nLandsat data\n\nThe second dataset is a simplified collection of bands (red, green, blue, near-infrared and shortwave infrared) from the Landsat Collection 2 Level-2 atmosperically corrected surface reflectance data, collected by the Landsat 8 satellite.\nInformation about Landsat bands from USGS:\nWhat are the band designations for the Landsat satellites? -Common Landsat Band Combinations\n-How do I use a scale factor with Landsat Level-2 science products?\nThe data was accessed and pre-processed in the Microsoft Planetary Computer to remove data outside land and coarsen the spatial resolution (Landsat Collection in MPC). Data should be used for visualization purposes only.\n\nShapefile of fire perimeters\n\nThe third dataset is a shapefile of fire perimeters in California during 2017. The complete file can be accessed in the CA state geoportal here: https://gis.data.ca.gov/datasets/CALFIRE-Forestry::california-fire-perimeters-all-1/about\n\n\n\nAirNow. (2021b). Air Quality Index (AQI) Basics. Retrieved from www.airnow.gov website: https://www.airnow.gov/aqi/aqi-basics/\nWikipedia Contributors. (2019, October 6). Thomas Fire. Retrieved from Wikipedia website: https://en.wikipedia.org/wiki/Thomas_Fire\nCalifornia Fire Perimeters (all). (n.d.). Retrieved November 29, 2023, from gis.data.ca.gov website: https://gis.data.ca.gov/datasets/CALFIRE-Forestry::california-fire-perimeters-all-1/about\nMicrosoft Planetary Computer. Planetary Computer. (n.d.). https://planetarycomputer.microsoft.com/dataset/landsat-c2-l2))\n\n\n\n\n\n\nCode\n## Importing data\n\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\nimport os\nimport numpy as np\nimport matplotlib.pyplot as plt\n\nimport rioxarray as rioxr\n\nimport geopandas as gpd\nfrom shapely.geometry import Polygon\n\n\nModuleNotFoundError: No module named 'pandas'\n\n\n\n\nCode\n## Download data\n\n# read in files using pd.read_csv\naqi_17 = pd.read_csv('https://aqs.epa.gov/aqsweb/airdata/daily_aqi_by_county_2017.zip')\naqi_18 = pd.read_csv('https://aqs.epa.gov/aqsweb/airdata/daily_aqi_by_county_2018.zip')\n\nlandsat = os.path.join(os.getcwd(),'data','landsat8-2018-01-26-sb-simplified.nc') #define path\nlandsat = rioxr.open_rasterio(landsat) #import\n\nfire = gpd.read_file('data/California_Fire_Perimeters/California_Fire_Perimeters_2017.shp')\n\n\nNameError: name 'pd' is not defined\n\n\n\n\n\n\n\nCode\n## Explore AQ data\n\n#use .info to explore data. date is an object.\naqi_17.info()\naqi_18.info()\n\n\n&lt;class 'pandas.core.frame.DataFrame'&gt;\nRangeIndex: 326801 entries, 0 to 326800\nData columns (total 10 columns):\n #   Column                     Non-Null Count   Dtype \n---  ------                     --------------   ----- \n 0   State Name                 326801 non-null  object\n 1   county Name                326801 non-null  object\n 2   State Code                 326801 non-null  int64 \n 3   County Code                326801 non-null  int64 \n 4   Date                       326801 non-null  object\n 5   AQI                        326801 non-null  int64 \n 6   Category                   326801 non-null  object\n 7   Defining Parameter         326801 non-null  object\n 8   Defining Site              326801 non-null  object\n 9   Number of Sites Reporting  326801 non-null  int64 \ndtypes: int64(4), object(6)\nmemory usage: 24.9+ MB\n&lt;class 'pandas.core.frame.DataFrame'&gt;\nRangeIndex: 327537 entries, 0 to 327536\nData columns (total 10 columns):\n #   Column                     Non-Null Count   Dtype \n---  ------                     --------------   ----- \n 0   State Name                 327537 non-null  object\n 1   county Name                327537 non-null  object\n 2   State Code                 327537 non-null  int64 \n 3   County Code                327537 non-null  int64 \n 4   Date                       327537 non-null  object\n 5   AQI                        327537 non-null  int64 \n 6   Category                   327537 non-null  object\n 7   Defining Parameter         327537 non-null  object\n 8   Defining Site              327537 non-null  object\n 9   Number of Sites Reporting  327537 non-null  int64 \ndtypes: int64(4), object(6)\nmemory usage: 25.0+ MB\n\n\n\n\nCode\n## Explore landsat data\n\n# update column names to small caps\nfire.columns = fire.columns.str.lower()\n\n\nCRS.from_epsg(32611)\n\n\n\n\n\n\n\nCode\n## Update AQ data\n\n# concatenate two dataframes\naqi = pd.concat([aqi_17, aqi_18])\n\n# see initial column names: notice caps and spaces (difficult to work with!)\naqi.columns, '\\n'\n\n# re-assign the column names - .str.lower() makes them lower case\naqi.columns = aqi.columns.str.lower()\naqi.columns, '\\n'\n\n#  re-assign the column names again - .str.replace(' ','_') replaces the space for _ \naqi.columns = aqi.columns.str.replace(' ','_')\naqi.columns, '\\n'\n\n# as a \"one liner\" you could achieve this column name cleaning like this:\n# aqi.columns = aqi.columns.str.lower().str.replace(' ','_')\n\n#select only data from SB county\naqi_sb = aqi[aqi['county_name'] == 'Santa Barbara']\n\n#remove state_name, county_name, state_code and county_code columns \naqi_sb.drop(['state_name', 'county_name', 'state_code', 'county_code'], axis=1)\n\n#use pd.to_datetime to update date column to be a datetime object from object\naqi_sb.date = pd.to_datetime(aqi_sb.date)\n\n#update index\naqi_sb = aqi_sb.set_index(\"date\")\n\n#datatype (dtype) is datetime64[ns]\n\n# rolling() is a method for pandas.series that provides rolling window calculations\n# the parameter '5D' indicates we want the window to be 5 days\n# This is a lazy method (think groupby), we need to specify what we want to calculate over each window\n# here we add the aggregator function mean()\n# this indicates we want the mean over each window\n# and we get a pd.Series as ouput\naqi_sb.aqi.rolling('5D').mean()\n\n# add mean of 5-day avg as new column with [] and .mean\naqi_sb['five_day_average'] = aqi_sb.aqi.rolling('5D').mean()\n\n\n/tmp/ipykernel_1661624/2365823.py:27: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  aqi_sb.date = pd.to_datetime(aqi_sb.date)\n\n\n\n\nCode\n## Update landsat and fire data\n\n# convert the fire crs to match landsat crs\nfire = fire.to_crs(landsat.rio.crs)\n\n#check that crs now matches\nlandsat.rio.crs == fire.crs\n\n# select thomas fire data\nthomas = fire.loc[fire['fire_name'] == \"THOMAS\"]\n\n#drop the band so we can plot later\nlandsat = landsat.squeeze().drop('band')\n\n\n\n\n\n\n\nCode\n## Plot and create image\n\n# plot daily AQI and 5-day avg\n\n#initialize plot\nplt.figure()\n\n#plot with 5-day avg on top of the AQI and customize labels and colors\naqi_sb.plot(y=['aqi', 'five_day_average'], title='AQI levels in SB', color = ['pink', 'yellow'])\n\n#The Thomas fire event in December of 2017 is visable on the plot as a high spike. \n\n\n&lt;AxesSubplot:title={'center':'AQI levels in SB'}, xlabel='date'&gt;\n\n\n&lt;Figure size 640x480 with 0 Axes&gt;\n\n\n\n\n\n\n\nCode\n# Plot Thomas fire\n\n#convert landsat CRS to match w fire CRS\nfire = fire.to_crs(landsat.rio.crs)\n\n# plot\nfig, ax = plt.subplots()\n\n# plot Thomas fire on top of the landsat plot by plotting landsat first, then thomas\nlandsat[['swir22', 'nir08', 'red']].to_array().plot.imshow(robust = True)\n\nthomas.plot(ax=ax, color = 'salmon', alpha = 0.5, edgecolor = 'purple')\n\n#set title name\nax.set_title('Thomas Fire in SB County', fontsize=12)\n\n\nText(0.5, 1.0, 'Thomas Fire in SB County')"
  },
  {
    "objectID": "blog/2023-12-13-thomas-fire/AQI_falsecolor.html#about",
    "href": "blog/2023-12-13-thomas-fire/AQI_falsecolor.html#about",
    "title": "AQI Analysis in Santa Barbara",
    "section": "",
    "text": "In this notebook, we use Air Quality Index (AQI) data from the US Environmental Protection Agency to visualize the impact on the AQI of the 2017 Thomas Fire in Santa Barbara County. We also will create a false color image showing the fire scar of the Thomas fire in 2017.\n\n\n\n\nFetch vector data from an online repository\nData wrangling and exploration of with pandas\nGeospatial data wrangling with geopandas\nCreating and customizing a line plot\nCreating and customizing a false color image\n\n\n\n\nIn this notebook we use three datasets:\n\nAir Quality Index (AQI) data from the US Environmental Protection Agency\n\nThe first dataset contains information about EPA’s index for reporting air quality.\nFor each pollutant an AQI value of 100 generally corresponds to an ambient air concentration that equals the level of the short-term national ambient air quality standard for protection of public health. AQI values at or below 100 are generally thought of as satisfactory. When AQI values are above 100, air quality is unhealthy: at first for certain sensitive groups of people, then for everyone as AQI values get higher.\nThe AQI is divided into six categories. Each category corresponds to a different level of health concern.\n\nLandsat data\n\nThe second dataset is a simplified collection of bands (red, green, blue, near-infrared and shortwave infrared) from the Landsat Collection 2 Level-2 atmosperically corrected surface reflectance data, collected by the Landsat 8 satellite.\nInformation about Landsat bands from USGS:\nWhat are the band designations for the Landsat satellites? -Common Landsat Band Combinations\n-How do I use a scale factor with Landsat Level-2 science products?\nThe data was accessed and pre-processed in the Microsoft Planetary Computer to remove data outside land and coarsen the spatial resolution (Landsat Collection in MPC). Data should be used for visualization purposes only.\n\nShapefile of fire perimeters\n\nThe third dataset is a shapefile of fire perimeters in California during 2017. The complete file can be accessed in the CA state geoportal here: https://gis.data.ca.gov/datasets/CALFIRE-Forestry::california-fire-perimeters-all-1/about\n\n\n\nAirNow. (2021b). Air Quality Index (AQI) Basics. Retrieved from www.airnow.gov website: https://www.airnow.gov/aqi/aqi-basics/\nWikipedia Contributors. (2019, October 6). Thomas Fire. Retrieved from Wikipedia website: https://en.wikipedia.org/wiki/Thomas_Fire\nCalifornia Fire Perimeters (all). (n.d.). Retrieved November 29, 2023, from gis.data.ca.gov website: https://gis.data.ca.gov/datasets/CALFIRE-Forestry::california-fire-perimeters-all-1/about\nMicrosoft Planetary Computer. Planetary Computer. (n.d.). https://planetarycomputer.microsoft.com/dataset/landsat-c2-l2))"
  },
  {
    "objectID": "blog/2023-12-13-thomas-fire/AQI_falsecolor.html#import-libraries",
    "href": "blog/2023-12-13-thomas-fire/AQI_falsecolor.html#import-libraries",
    "title": "AQI Analysis in Santa Barbara",
    "section": "",
    "text": "Code\n## Importing data\n\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\nimport os\nimport numpy as np\nimport matplotlib.pyplot as plt\n\nimport rioxarray as rioxr\n\nimport geopandas as gpd\nfrom shapely.geometry import Polygon\n\n\nModuleNotFoundError: No module named 'pandas'\n\n\n\n\nCode\n## Download data\n\n# read in files using pd.read_csv\naqi_17 = pd.read_csv('https://aqs.epa.gov/aqsweb/airdata/daily_aqi_by_county_2017.zip')\naqi_18 = pd.read_csv('https://aqs.epa.gov/aqsweb/airdata/daily_aqi_by_county_2018.zip')\n\nlandsat = os.path.join(os.getcwd(),'data','landsat8-2018-01-26-sb-simplified.nc') #define path\nlandsat = rioxr.open_rasterio(landsat) #import\n\nfire = gpd.read_file('data/California_Fire_Perimeters/California_Fire_Perimeters_2017.shp')\n\n\nNameError: name 'pd' is not defined"
  },
  {
    "objectID": "blog/2023-12-13-thomas-fire/AQI_falsecolor.html#explore-data",
    "href": "blog/2023-12-13-thomas-fire/AQI_falsecolor.html#explore-data",
    "title": "AQI Analysis in Santa Barbara",
    "section": "",
    "text": "Code\n## Explore AQ data\n\n#use .info to explore data. date is an object.\naqi_17.info()\naqi_18.info()\n\n\n&lt;class 'pandas.core.frame.DataFrame'&gt;\nRangeIndex: 326801 entries, 0 to 326800\nData columns (total 10 columns):\n #   Column                     Non-Null Count   Dtype \n---  ------                     --------------   ----- \n 0   State Name                 326801 non-null  object\n 1   county Name                326801 non-null  object\n 2   State Code                 326801 non-null  int64 \n 3   County Code                326801 non-null  int64 \n 4   Date                       326801 non-null  object\n 5   AQI                        326801 non-null  int64 \n 6   Category                   326801 non-null  object\n 7   Defining Parameter         326801 non-null  object\n 8   Defining Site              326801 non-null  object\n 9   Number of Sites Reporting  326801 non-null  int64 \ndtypes: int64(4), object(6)\nmemory usage: 24.9+ MB\n&lt;class 'pandas.core.frame.DataFrame'&gt;\nRangeIndex: 327537 entries, 0 to 327536\nData columns (total 10 columns):\n #   Column                     Non-Null Count   Dtype \n---  ------                     --------------   ----- \n 0   State Name                 327537 non-null  object\n 1   county Name                327537 non-null  object\n 2   State Code                 327537 non-null  int64 \n 3   County Code                327537 non-null  int64 \n 4   Date                       327537 non-null  object\n 5   AQI                        327537 non-null  int64 \n 6   Category                   327537 non-null  object\n 7   Defining Parameter         327537 non-null  object\n 8   Defining Site              327537 non-null  object\n 9   Number of Sites Reporting  327537 non-null  int64 \ndtypes: int64(4), object(6)\nmemory usage: 25.0+ MB\n\n\n\n\nCode\n## Explore landsat data\n\n# update column names to small caps\nfire.columns = fire.columns.str.lower()\n\n\nCRS.from_epsg(32611)"
  },
  {
    "objectID": "blog/2023-12-13-thomas-fire/AQI_falsecolor.html#manipulate-data-in-order-to-plot",
    "href": "blog/2023-12-13-thomas-fire/AQI_falsecolor.html#manipulate-data-in-order-to-plot",
    "title": "AQI Analysis in Santa Barbara",
    "section": "",
    "text": "Code\n## Update AQ data\n\n# concatenate two dataframes\naqi = pd.concat([aqi_17, aqi_18])\n\n# see initial column names: notice caps and spaces (difficult to work with!)\naqi.columns, '\\n'\n\n# re-assign the column names - .str.lower() makes them lower case\naqi.columns = aqi.columns.str.lower()\naqi.columns, '\\n'\n\n#  re-assign the column names again - .str.replace(' ','_') replaces the space for _ \naqi.columns = aqi.columns.str.replace(' ','_')\naqi.columns, '\\n'\n\n# as a \"one liner\" you could achieve this column name cleaning like this:\n# aqi.columns = aqi.columns.str.lower().str.replace(' ','_')\n\n#select only data from SB county\naqi_sb = aqi[aqi['county_name'] == 'Santa Barbara']\n\n#remove state_name, county_name, state_code and county_code columns \naqi_sb.drop(['state_name', 'county_name', 'state_code', 'county_code'], axis=1)\n\n#use pd.to_datetime to update date column to be a datetime object from object\naqi_sb.date = pd.to_datetime(aqi_sb.date)\n\n#update index\naqi_sb = aqi_sb.set_index(\"date\")\n\n#datatype (dtype) is datetime64[ns]\n\n# rolling() is a method for pandas.series that provides rolling window calculations\n# the parameter '5D' indicates we want the window to be 5 days\n# This is a lazy method (think groupby), we need to specify what we want to calculate over each window\n# here we add the aggregator function mean()\n# this indicates we want the mean over each window\n# and we get a pd.Series as ouput\naqi_sb.aqi.rolling('5D').mean()\n\n# add mean of 5-day avg as new column with [] and .mean\naqi_sb['five_day_average'] = aqi_sb.aqi.rolling('5D').mean()\n\n\n/tmp/ipykernel_1661624/2365823.py:27: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  aqi_sb.date = pd.to_datetime(aqi_sb.date)\n\n\n\n\nCode\n## Update landsat and fire data\n\n# convert the fire crs to match landsat crs\nfire = fire.to_crs(landsat.rio.crs)\n\n#check that crs now matches\nlandsat.rio.crs == fire.crs\n\n# select thomas fire data\nthomas = fire.loc[fire['fire_name'] == \"THOMAS\"]\n\n#drop the band so we can plot later\nlandsat = landsat.squeeze().drop('band')"
  },
  {
    "objectID": "blog/2023-12-13-thomas-fire/AQI_falsecolor.html#create-data-visuals",
    "href": "blog/2023-12-13-thomas-fire/AQI_falsecolor.html#create-data-visuals",
    "title": "AQI Analysis in Santa Barbara",
    "section": "",
    "text": "Code\n## Plot and create image\n\n# plot daily AQI and 5-day avg\n\n#initialize plot\nplt.figure()\n\n#plot with 5-day avg on top of the AQI and customize labels and colors\naqi_sb.plot(y=['aqi', 'five_day_average'], title='AQI levels in SB', color = ['pink', 'yellow'])\n\n#The Thomas fire event in December of 2017 is visable on the plot as a high spike. \n\n\n&lt;AxesSubplot:title={'center':'AQI levels in SB'}, xlabel='date'&gt;\n\n\n&lt;Figure size 640x480 with 0 Axes&gt;\n\n\n\n\n\n\n\nCode\n# Plot Thomas fire\n\n#convert landsat CRS to match w fire CRS\nfire = fire.to_crs(landsat.rio.crs)\n\n# plot\nfig, ax = plt.subplots()\n\n# plot Thomas fire on top of the landsat plot by plotting landsat first, then thomas\nlandsat[['swir22', 'nir08', 'red']].to_array().plot.imshow(robust = True)\n\nthomas.plot(ax=ax, color = 'salmon', alpha = 0.5, edgecolor = 'purple')\n\n#set title name\nax.set_title('Thomas Fire in SB County', fontsize=12)\n\n\nText(0.5, 1.0, 'Thomas Fire in SB County')"
  },
  {
    "objectID": "blog/2023-10-23-my-first-post/index.html",
    "href": "blog/2023-10-23-my-first-post/index.html",
    "title": "Liane’s first blog post",
    "section": "",
    "text": "Here is some really1 exciting stuff!\nI love MEDS so much"
  },
  {
    "objectID": "blog/2023-10-23-my-first-post/index.html#this-is-my-first-section",
    "href": "blog/2023-10-23-my-first-post/index.html#this-is-my-first-section",
    "title": "Liane’s first blog post",
    "section": "",
    "text": "Here is some really1 exciting stuff!\nI love MEDS so much"
  },
  {
    "objectID": "blog/2023-10-23-my-first-post/index.html#this-is-my-second-section",
    "href": "blog/2023-10-23-my-first-post/index.html#this-is-my-second-section",
    "title": "Liane’s first blog post",
    "section": "This is my second section",
    "text": "This is my second section\nYay"
  },
  {
    "objectID": "blog/2023-10-23-my-first-post/index.html#footnotes",
    "href": "blog/2023-10-23-my-first-post/index.html#footnotes",
    "title": "Liane’s first blog post",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nThis is my first footnote↩︎"
  },
  {
    "objectID": "blog/2023-12-15-HOLC-redlining/HOLC_redlining.html",
    "href": "blog/2023-12-15-HOLC-redlining/HOLC_redlining.html",
    "title": "Historical Redlining and Bird Sampling Disparity",
    "section": "",
    "text": "What impact on bird biodiversity sampling does historical redlining have in Los Angeles County?"
  },
  {
    "objectID": "blog/2023-12-15-HOLC-redlining/HOLC_redlining.html#research-question",
    "href": "blog/2023-12-15-HOLC-redlining/HOLC_redlining.html#research-question",
    "title": "Historical Redlining and Bird Sampling Disparity",
    "section": "",
    "text": "What impact on bird biodiversity sampling does historical redlining have in Los Angeles County?"
  },
  {
    "objectID": "blog/2023-12-15-HOLC-redlining/HOLC_redlining.html#background",
    "href": "blog/2023-12-15-HOLC-redlining/HOLC_redlining.html#background",
    "title": "Historical Redlining and Bird Sampling Disparity",
    "section": "Background",
    "text": "Background\nPresent-day environmental justice may reflect legacies of injustice in the past. The United States has a long history of racial segregation which is still visible. During the 1930’s the Home Owners’ Loan Corporation (HOLC), as part of the New Deal, rated neighborhoods based on their perceived safety for real estate investment. Their ranking system, (A (green), B (blue), C (yellow), D (red)) was then used to block access to loans for home ownership. Colloquially known as “redlining”, this practice has had widely-documented consequences not only for community wealth, but also health (Gee 2008). Redlined neighborhoods have less greenery and are hotter than other neighborhoods (Nardone, 2021; Hoffman, 2020).\nCheck out coverage by the New York Times.\nA recent study found that redlining has not only affected the environments communities are exposed to, it has also shaped our observations of biodiversity (Ellis-Soto, 2023). Community or citizen science, whereby individuals share observations of species, is generating an enormous volume of data. Ellis-Soto and co-authors found that historically redlining neighborhoods remain the most undersampled areas across 195 US cities. This gap is highly concerning, because conservation decisions are made based on these data.\nCheck out coverage by EOS.\nAlso check out coverage on historical redlining and its impact on bird populations in LA by [LAist]."
  },
  {
    "objectID": "blog/2023-12-15-HOLC-redlining/HOLC_redlining.html#data",
    "href": "blog/2023-12-15-HOLC-redlining/HOLC_redlining.html#data",
    "title": "Historical Redlining and Bird Sampling Disparity",
    "section": "Data",
    "text": "Data\nThe datasets used for this analysis are listed and described below:\n\nEJScreen\n\nThis data is provided by the United States Environmental Protection Agency’s EJScreen: Environmental Justice Screening and Mapping Tool.\nAccording to the US EPA website:\n\nThis screening tool and data may be of interest to community residents or other stakeholders as they search for environmental or demographic information. It can also support a wide range of research and policy goals. The public has used EJScreen in many different locations and in many different ways.\nEPA is sharing EJScreen with the public:\n\nto be more transparent about how we consider environmental justice in our work\nto assist our stakeholders in making informed decisions about pursuing environmental justice and,\nto create a common starting point between the agency and the public when looking at issues related to environmental justice.\n\n\n\nEJScreen\n\nEJScreen provides on environmental and demographic information for the US at the Census tract and block group levels. We will be working with block group data that has been downloaded from the EPA site. To understand the associated data columns, we will need to explore the Technical Documentation and column description spreadsheet available. We can also explore the limitations and caveats of the data.\n\nMapping Inequality (University of Richmond)\n\nA team of researchers, led by the Digital Scholarship Lab at the University of Richmond have digitized maps and information from the HOLC as part of the Mapping Inequality project.\nMaps of HOLC grade designations for Los Angeles will be used. Information on the data can be found here (Robert 2023).\n\nGlobal Biodiversity Information Facility\n\nThe Global Biodiversity Information Facility is the largest aggregator of biodiversity observations in the world. Observations typically include a location and date that a species was observed.\nObservations of birds from 2021 onward will be used."
  },
  {
    "objectID": "blog/2023-12-15-HOLC-redlining/HOLC_redlining.html#data-analysis",
    "href": "blog/2023-12-15-HOLC-redlining/HOLC_redlining.html#data-analysis",
    "title": "Historical Redlining and Bird Sampling Disparity",
    "section": "Data Analysis",
    "text": "Data Analysis\n\nAnalysis of EJScreen data within a historical redlining context\nWe will investigate the legacy of redlining in current environmental (in)justice by exploring and visualize the data. Using these summaries and visualization, we can then draw conclusions on our research question.\n\n\nImport and explore data\nFirst, we need to load the relevant packages.\n\n# Load the libraries needed for the analysis\nlibrary(tidyverse)\nlibrary(sf)\nlibrary(terra)\nlibrary(dplyr)\nlibrary(spData)\nlibrary(spDataLarge)\nlibrary(ggplot2)\nlibrary(tmap)\n\nNext, we will read in EJScreen data and filter to Los Angeles County.\n\n# Read in geodatabase of EJScreen data at the Census Block Group level\nejscreen &lt;- st_read(\"data/EJSCREEN_2023_BG_StatePct_with_AS_CNMI_GU_VI.gdb/\") \n\n#check class of ejscreen\nclass(ejscreen)\n\n\n# Filter to Los Angeles County\nla_county &lt;- ejscreen %&gt;%\n  filter(CNTY_NAME %in% c(\"Los Angeles County\"))\n\nWe can now make a map of wastewater discharge by census block groups. We can indicate which census block groups are above the 95th percentile of national values for wastewater discharge by adding a centroid.\n\n# Pipe in la_county and filter to wastewater discharge column. Define as a variable so we can use later\nla_95 &lt;- la_county %&gt;%\n  filter (P_PWDIS &gt; 95)\n\n# Find the centroid within each Census Block Group above 95 percentile, so you can plot that as points\nla_95_centroids &lt;- st_centroid(la_95)\n\n# Create map that shows LA county census block groups by percentile and denote those above the 95 percentile in red.\n\nmap1 &lt;- tm_shape(la_county) + #first layer\n  tm_fill(\"P_PWDIS\", title = \"Wastewater Discharge in LA by Percentile\") + #use P_PWDIS as variable to map\n  tm_shape(la_95_centroids) + #second layer\n  tm_dots(fill = \"red\", #map data points for la_95_centroids\n          size = 0.03) + \n  tm_scale_bar(position=c(\"right\", \"bottom\"), size = 0.2) + #the rest is formatting\n  tm_compass(type=\"arrow\", position=c(\"right\", \"bottom\"), size = 0.5, show.labels = 1) +\n  tm_layout(legend.outside = FALSE,\n              legend.stack = \"horizontal\",\n              legend.outside.position = \"bottom\",\n              legend.outside.size = 0.5, \n              legend.text.size = 0.75,\n              legend.title.size=0.75)\n\n# Print the map\nmap1\n\n\n\n\nWe can look at income disparity by finding the percent of census block groups that have:\n- less than 5% of the population is considered low income\n\n# Create a subset data with low income percentile (column 19, LOWINCPCT) and create condition for less than 5% \nla_lowincpct &lt;- subset(la_county, LOWINCPCT &lt; 0.05)\n\n# Count the total number of rows in la_lowincpct \nnrow(la_lowincpct) #403 rows (403 census blocks that have less than 5% of low income pop)\n\n[1] 403\n\n# Count the total number of rows in la_county\nnrow(la_county) #6591 rows (6591 census blocks total in LA)\n\n[1] 6591\n\n# Divide number of census block groups with less than 5% of low income population by the total number of census block groups and multiply by 100 to get the percentage\n(nrow(la_lowincpct) / nrow(la_county)) * 100  \n\n[1] 6.114398\n\n\nWe can see above that 6.11 percent of census block groups have less than 5% of low income populations.\nNext, let’s find the percent of census block groups that are:\n- above the 80th percentile for Particulate Matter 2.5 AND\n- above the 80th percentile for Superfund proximity\n\n# column 81, P_PM25 is percentile for PM 2.5\n# column 89, P_PNPL is percentile for Superfund proximity\n# now filter to these specific parameters\n\nPM25_PNPL_80 &lt;- la_county %&gt;%\n  filter(P_PM25 &gt; 80 & P_PNPL &gt; 80) \n\n#count the number of observations \nnrow(PM25_PNPL_80) #there are 1144 census block groups above the 80th percentiles for PM2.5 and PNPL\n\n[1] 1144\n\n# turn this into a percentage\n(nrow(PM25_PNPL_80)/ nrow(la_county)) * 100\n\n[1] 17.357\n\n\nIn order to interpret historical redlining impacts, we need to start by importing redlining information for Los Angeles.\n\n#use st_read to import redlining information\nLA_redlining &lt;- st_read(\"https://dsl.richmond.edu/panorama/redlining/static/citiesData/CALosAngeles1939/geojson.json\") %&gt;%\n  st_make_valid()\n\nReading layer `geojson' from data source \n  `https://dsl.richmond.edu/panorama/redlining/static/citiesData/CALosAngeles1939/geojson.json' \n  using driver `GeoJSON'\nSimple feature collection with 417 features and 14 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: -118.6104 ymin: 33.70563 xmax: -117.7028 ymax: 34.30388\nGeodetic CRS:  WGS 84\n\n\nLet’s make a map of historical redlining boundaries, colored by HOLC grade.\n\n#create the map\nmap2 &lt;-\n  tm_shape(LA_redlining) + #first layer\n    tm_fill(\"grade\", #use holc_grade as the variable to map\n            title =  \"HOLC Grade\",\n            col_alpha = 0.2) + #pretty\n    #tm_graticules(col_alpha = 0.2) + #add graticules\n  tm_shape(la_county) + #second layer\n    tm_borders(\"grey25\", col_alpha = 0.2) + #rest is formatting\n    tm_xlab('longitude', size = 0.8, rotation = 0, space = 0) + #create x/y labels\n    tm_ylab('latitude', size = 0.8, rotation = 90, space = 0) +\n    tm_compass(type=\"arrow\", position=c(\"RIGHT\", \"BOTTOM\"), size = 0.5, show.labels = 1) +\n    tm_scale_bar(position=c(\"RIGHT\", \"BOTTOM\"), breaks = c(0, 10, 20), size = 0.5) +\n    #tm_title(\"test\", position = tm_pos(\"left\", \"top\")) +\n  tm_layout(legend.title.size = 0.5,\n            legend.text.size = 0.6,\n            legend.position = c(\"right\",\"top\")\n            )\n\n#print the map  \nmap2\n\n\n\n\nWe want to find the number of census block groups that fall within areas with HOLC grades. In order to do so, we must make sure the CRS match.\n\n#check that the CRS match\nst_crs(LA_redlining) == st_crs(la_county)\n\n[1] FALSE\n\n\n\nst_crs(LA_redlining) # show ID[\"EPSG\",4326]\nst_crs(la_county) # show ID[\"EPSG\",3857]\n\n\n#transform la_county to match crs with LA_redlining \nla_county &lt;- st_transform(la_county, crs = 4326)\n\n#check that crs has been transformed\nst_crs(la_county) #confirmed, they match\n\nCoordinate Reference System:\n  User input: EPSG:4326 \n  wkt:\nGEOGCRS[\"WGS 84\",\n    ENSEMBLE[\"World Geodetic System 1984 ensemble\",\n        MEMBER[\"World Geodetic System 1984 (Transit)\"],\n        MEMBER[\"World Geodetic System 1984 (G730)\"],\n        MEMBER[\"World Geodetic System 1984 (G873)\"],\n        MEMBER[\"World Geodetic System 1984 (G1150)\"],\n        MEMBER[\"World Geodetic System 1984 (G1674)\"],\n        MEMBER[\"World Geodetic System 1984 (G1762)\"],\n        MEMBER[\"World Geodetic System 1984 (G2139)\"],\n        ELLIPSOID[\"WGS 84\",6378137,298.257223563,\n            LENGTHUNIT[\"metre\",1]],\n        ENSEMBLEACCURACY[2.0]],\n    PRIMEM[\"Greenwich\",0,\n        ANGLEUNIT[\"degree\",0.0174532925199433]],\n    CS[ellipsoidal,2],\n        AXIS[\"geodetic latitude (Lat)\",north,\n            ORDER[1],\n            ANGLEUNIT[\"degree\",0.0174532925199433]],\n        AXIS[\"geodetic longitude (Lon)\",east,\n            ORDER[2],\n            ANGLEUNIT[\"degree\",0.0174532925199433]],\n    USAGE[\n        SCOPE[\"Horizontal component of 3D system.\"],\n        AREA[\"World.\"],\n        BBOX[-90,-180,90,180]],\n    ID[\"EPSG\",4326]]\n\n# Find the number of census block groups that fall within areas with HOLC grades by counting number of rows \n\ncensus_holc = st_join(LA_redlining, la_county, join = st_intersects)\n\nnrow(distinct(census_holc)) #6090 distinct rows\n\n[1] 6388\n\n\nIn order to interpret our data, we need to summarize current conditions based on EJScreen data within historical redlining categories using the mean of the following variables:\n- % low income.\n- percentile for particulate Matter 2.5.\n- percentile for low life expectancy.\n- percentile for air toxics cancer risk\n\n#calculate mean by using mean(df$my_column) for variables:\n\n## % low income\nmean_lowinc &lt;- mean(census_holc$P_LOWINCPCT)\n\n## % for particulate Matter 2.5\nmean_pm25 &lt;- mean(census_holc$P_PM25)\n\n## % for low life expectancy\nmean_lowlife &lt;- mean(census_holc$P_LIFEEXPPCT, na.rm=TRUE)\n\n## % for air toxics cancer risk\nmean_cancer &lt;- mean(census_holc$P_CANCER, na.rm=TRUE)\n\n#print mean values for variables\nmean_lowinc\n\n[1] 55.90059\n\nmean_pm25\n\n[1] 78.07185\n\nmean_lowlife\n\n[1] 45.33147\n\nmean_cancer\n\n[1] 52.3011\n\n\n\n\nConclusion\nThe mean for the particulate matter 2.5 percentile is much higher than the other mean percentiles, which suggests that HOLC neighborhoods may have shorter setback distances from particulate matter emitting sources, such as industrial and transportation lands with hazardous uses. While lower than pm2.5, the other percentiles are still alarmingly high, given that low life expectancy and cancer are severe conditions. The percentiles for low income and cancer neighborhoods are similar and the percentile for low life expectancy is a bit lower.\n\n\nInvestigate the legacy of redlining in biodiversity observations\nFor bird observations from 2022 that fall within neighborhoods with HOLC grads, we will find the percent of observations within each redlining categories and plot results. In order to do so, we must make sure that the bird observations have the same CRS as redlining data.\n\n\nImport and explore data\nWe will start by importing exploring data.\n\n#read in bird data from data folder\nbird &lt;- st_read(\"data/gbif-birds-LA/gbif-birds-LA.shp\") \n\n#filter to year 2022\nbird_2022 &lt;- bird %&gt;% filter(year == 2022)\n\n#check crs\nst_crs(LA_redlining) == st_crs(bird) #True\n\n#intersect birds and LA redlining\nbird_red &lt;- st_join(LA_redlining, bird_2022, join = st_intersects)\n\nLet’s find the percent of observations within each redlining category.\n\nbird_holc_p &lt;- bird_red %&gt;% #filter into the intersected data defined above\n  st_drop_geometry() %&gt;% #drop the geometry column  \n  group_by(grade) %&gt;% #group by values in holc_grade column\n  summarise(percentage = n()/nrow(bird_red) * 100) #summarise these group by percentage\n\n#print\nbird_holc_p\n\n# A tibble: 5 × 2\n  grade percentage\n  &lt;chr&gt;      &lt;dbl&gt;\n1 A          15.0 \n2 B          18.8 \n3 C          34.3 \n4 D          28.1 \n5 &lt;NA&gt;        3.80\n\n\nLet’s plot this to visualize the percent of bird observations within each redlining category.\n\n# plot \nggplot(bird_holc_p, \n       aes(x=grade, y=percentage)) + #label x/y axis\n       labs(title = \"Percent of Bird Observations within each Redlining Category\") + \n       geom_col(fill = \"cornflowerblue\") #customize labels\n\n\n\n\n\n\nConclusion\nThese results are surprising, given that the EOP article about birding discusses less available birding data in neighborhoods with historical redlining and its relation to decreased conservation efforts.\nThe graph shows that there are higher percentage of bird observations in the “C =”definitely declining” category, which could suggest a few possibilities:\n\nMore densely populated areas are in the C category and therefore more observations were recorded;\nThat the urban infrastructure is deteriorating so much that it results in increased green spaces with suitable bird habitat, or;\nThere is increased gentrification in these areas."
  },
  {
    "objectID": "blog/2023-12-15-HOLC-redlining/HOLC_redlining.html#references",
    "href": "blog/2023-12-15-HOLC-redlining/HOLC_redlining.html#references",
    "title": "Historical Redlining and Bird Sampling Disparity",
    "section": "References",
    "text": "References\n\nData\n\nUnited States Environmental Protection Agency’s EJScreen: Environmental Justice Screening and Mapping Tool: https://www.epa.gov/ejscreen/purposes-and-uses-ejscreen\nMapping Inequality (University of Richmond): https://dsl.richmond.edu/panorama/redlining/#loc=5/39.1/-94.58&text=downloads\nGlobal Biodiversity Information Facility: gbif.org\n\n\n\nLiterature\n\nGee, G. C. (2008). A multilevel analysis of the relationship between institutional and individual racial discrimination and health status. American journal of public health, 98(Supplement_1), S48-S56.\nNardone, A., Rudolph, K. E., Morello-Frosch, R., & Casey, J. A. (2021). Redlines and greenspace: the relationship between historical redlining and 2010 greenspace across the United States. Environmental health perspectives, 129(1), 017006.\nHoffman, J. S., Shandas, V., & Pendleton, N. (2020). The effects of historical housing policies on resident exposure to intra-urban heat: a study of 108 US urban areas. Climate, 8(1), 12.\nEllis-Soto, D., Chapman, M., & Locke, D. H. (2023). Historical redlining is associated with increasing geographical disparities in bird biodiversity sampling in the United States. Nature Human Behaviour, 1-9.\nRobert K. Nelson, LaDale Winling, Richard Marciano, Nathan Connolly, et al., “Mapping Inequality,” American Panorama, ed. Robert K. Nelson and Edward L. Ayers, accessed October 17, 2023, https://dsl.richmond.edu/panorama/redlining/"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "LIANE CHEN",
    "section": "",
    "text": "Professional Bio\nI expect to graduate in June 2023 with a Masters of Environmental Data Science. I am looking to use my passion for climate adaptation, environmental planning, and data science skills to prepare our communities and ecosystems to be more resilient to extreme climate impacts. I am especially interested in visualizing complex data and providing solutions to pressing environmental concerns in accessible and inclusive ways.\nEducation\nBren School of Environmental Science & Management, University of California, Santa Barbara (UCSB)\nMaster of Environmental Data Science (MEDS) | 2024\nUniversity of California, San Diego (UCSD)\nBachelor of Arts in Environmental Studies | 2012\nEmphasis: Policy, Planning"
  },
  {
    "objectID": "blog/python-notebook-render/STAC-search.html",
    "href": "blog/python-notebook-render/STAC-search.html",
    "title": "Exercise",
    "section": "",
    "text": "import numpy as np\nimport geopandas as gpd\nimport rioxarray as rioxr\nimport matplotlib.pyplot as plt\n\nfrom shapely.geometry import Polygon\n\n# used to access STAC catalogues\nfrom pystac_client import Client\n\n#used to sign items from the MPC STAC catalog\nimport planetary_computer\n\n# other libraries for nice outputs\nfrom IPython.display import Image\n\nAccess\n\n# access catalog\ncatalog = Client.open(\n    \"https://planetarycomputer.microsoft.com/api/stac/v1\", \n    modifier = planetary_computer.sign_inplace)\n\n\nThe 'modifer\n\n\nprint('Title: ', catalog.title)\nprint('Description: ', catalog.description)\n\nTitle:  Microsoft Planetary Computer STAC API\nDescription:  Searchable spatiotemporal metadata describing Earth science datasets hosted by the Microsoft Planetary Computer\n\n\n\ncatalog.get_collections()\n\n&lt;generator object Client.get_collections at 0x7788ea650150&gt;\n\n\n\n# get collections and print their names\ncollections = list(catalog.get_collections())\n\nprint ('Number of collections: ', len(collections))\nprint('Collections IDs: ')\nfor collection in collections:\n    print('-', collection.id)\n\nNumber of collections:  122\nCollections IDs: \n- daymet-annual-pr\n- daymet-daily-hi\n- 3dep-seamless\n- 3dep-lidar-dsm\n- fia\n- sentinel-1-rtc\n- gridmet\n- daymet-annual-na\n- daymet-monthly-na\n- daymet-annual-hi\n- daymet-monthly-hi\n- daymet-monthly-pr\n- gnatsgo-tables\n- hgb\n- cop-dem-glo-30\n- cop-dem-glo-90\n- goes-cmi\n- terraclimate\n- nasa-nex-gddp-cmip6\n- gpm-imerg-hhr\n- gnatsgo-rasters\n- 3dep-lidar-hag\n- 3dep-lidar-intensity\n- 3dep-lidar-pointsourceid\n- mtbs\n- noaa-c-cap\n- 3dep-lidar-copc\n- modis-64A1-061\n- alos-fnf-mosaic\n- 3dep-lidar-returns\n- mobi\n- landsat-c2-l2\n- era5-pds\n- chloris-biomass\n- kaza-hydroforecast\n- planet-nicfi-analytic\n- modis-17A2H-061\n- modis-11A2-061\n- daymet-daily-pr\n- 3dep-lidar-dtm-native\n- 3dep-lidar-classification\n- 3dep-lidar-dtm\n- gap\n- modis-17A2HGF-061\n- planet-nicfi-visual\n- gbif\n- modis-17A3HGF-061\n- modis-09A1-061\n- alos-dem\n- alos-palsar-mosaic\n- deltares-water-availability\n- modis-16A3GF-061\n- modis-21A2-061\n- us-census\n- jrc-gsw\n- deltares-floods\n- modis-43A4-061\n- modis-09Q1-061\n- modis-14A1-061\n- hrea\n- modis-13Q1-061\n- modis-14A2-061\n- sentinel-2-l2a\n- modis-15A2H-061\n- modis-11A1-061\n- modis-15A3H-061\n- modis-13A1-061\n- daymet-daily-na\n- nrcan-landcover\n- modis-10A2-061\n- ecmwf-forecast\n- noaa-mrms-qpe-24h-pass2\n- sentinel-1-grd\n- nasadem\n- io-lulc\n- landsat-c2-l1\n- drcog-lulc\n- chesapeake-lc-7\n- chesapeake-lc-13\n- chesapeake-lu\n- noaa-mrms-qpe-1h-pass1\n- noaa-mrms-qpe-1h-pass2\n- noaa-nclimgrid-monthly\n- goes-glm\n- usda-cdl\n- eclipse\n- esa-cci-lc\n- esa-cci-lc-netcdf\n- fws-nwi\n- usgs-lcmap-conus-v13\n- usgs-lcmap-hawaii-v10\n- noaa-climate-normals-tabular\n- noaa-climate-normals-netcdf\n- noaa-climate-normals-gridded\n- aster-l1t\n- cil-gdpcir-cc-by-sa\n- io-lulc-9-class\n- io-biodiversity\n- naip\n- noaa-cdr-sea-surface-temperature-whoi\n- noaa-cdr-ocean-heat-content\n- cil-gdpcir-cc0\n- cil-gdpcir-cc-by\n- noaa-cdr-sea-surface-temperature-whoi-netcdf\n- noaa-cdr-sea-surface-temperature-optimum-interpolation\n- modis-10A1-061\n- sentinel-5p-l2-netcdf\n- sentinel-3-olci-wfr-l2-netcdf\n- noaa-cdr-ocean-heat-content-netcdf\n- sentinel-3-synergy-aod-l2-netcdf\n- sentinel-3-synergy-v10-l2-netcdf\n- sentinel-3-olci-lfr-l2-netcdf\n- sentinel-3-sral-lan-l2-netcdf\n- sentinel-3-slstr-lst-l2-netcdf\n- sentinel-3-slstr-wst-l2-netcdf\n- sentinel-3-sral-wat-l2-netcdf\n- ms-buildings\n- sentinel-3-slstr-frp-l2-netcdf\n- sentinel-3-synergy-syn-l2-netcdf\n- sentinel-3-synergy-vgp-l2-netcdf\n- sentinel-3-synergy-vg1-l2-netcdf\n- esa-worldcover\n\n\n\nnaip_collection = catalog.get_child('naip')\nnaip_collection\n\n\n\n\n    \n    \n    \n        \n            \n                \n                    CollectionClient: naip\n                \n            \n            \n\n\n\n\n\n\nid: naip\n\n\ntitle: NAIP: National Agriculture Imagery Program\n\n\ndescription: The [National Agriculture Imagery Program](https://www.fsa.usda.gov/programs-and-services/aerial-photography/imagery-programs/naip-imagery/) (NAIP) provides U.S.-wide, high-resolution aerial imagery, with four spectral bands (R, G, B, IR). NAIP is administered by the [Aerial Field Photography Office](https://www.fsa.usda.gov/programs-and-services/aerial-photography/) (AFPO) within the [US Department of Agriculture](https://www.usda.gov/) (USDA). Data are captured at least once every three years for each state. This dataset represents NAIP data from 2010-present, in [cloud-optimized GeoTIFF](https://www.cogeo.org/) format.\n\n\nproviders:\n\n\nUSDA Farm Service Agency (producer, licensor)\n\n\nEsri (processor)\n\n\nMicrosoft (host, processor)\n\n\n\n\ntype: Collection\n\n\nitem_assets: {'image': {'type': 'image/tiff; application=geotiff; profile=cloud-optimized', 'roles': ['data'], 'title': 'RGBIR COG tile', 'eo:bands': [{'name': 'Red', 'common_name': 'red'}, {'name': 'Green', 'common_name': 'green'}, {'name': 'Blue', 'common_name': 'blue'}, {'name': 'NIR', 'common_name': 'nir', 'description': 'near-infrared'}]}, 'metadata': {'type': 'text/plain', 'roles': ['metadata'], 'title': 'FGDC Metdata'}, 'thumbnail': {'type': 'image/jpeg', 'roles': ['thumbnail'], 'title': 'Thumbnail'}}\n\n\nmsft:region: westeurope\n\n\nmsft:container: naip\n\n\nmsft:storage_account: naipeuwest\n\n\nmsft:short_description: NAIP provides US-wide, high-resolution aerial imagery. This dataset includes NAIP images from 2010 to the present.\n\n\n\n\nSTAC Extensions\n\n\n\nhttps://stac-extensions.github.io/item-assets/v1.0.0/schema.json\n\n\nhttps://stac-extensions.github.io/table/v1.2.0/schema.json\n\n\n\n\n\nItems\nOnly the first item shown\n\n\n\n\n\nItem: hi_m_2015561_sw_05_060_20211226_20220909\n\n\n\nid: hi_m_2015561_sw_05_060_20211226_20220909\n\n\nbbox: [-155.502923, 19.997278, -155.434587, 20.065225]\n\n\ngsd: 0.6\n\n\ndatetime: 2021-12-26T16:00:00Z\n\n\nnaip:year: 2021\n\n\nproj:bbox: [238224.0, 2213136.0, 245268.0, 2220558.0]\n\n\nproj:epsg: 26905\n\n\nproviders: [{'url': 'https://www.fsa.usda.gov/programs-and-services/aerial-photography/imagery-programs/naip-imagery/', 'name': 'USDA Farm Service Agency', 'roles': ['producer', 'licensor']}]\n\n\nnaip:state: hi\n\n\nproj:shape: [12370, 11740]\n\n\nproj:transform: [0.6, 0.0, 238224.0, 0.0, -0.6, 2220558.0, 0.0, 0.0, 1.0]\n\n\n\n\nSTAC Extensions\n\n\n\nhttps://stac-extensions.github.io/eo/v1.0.0/schema.json\n\n\nhttps://stac-extensions.github.io/projection/v1.0.0/schema.json\n\n\n\n\n\nAssets\n\n\n\n\n\nAsset: RGBIR COG tile\n\n\n\nhref: https://naipeuwest.blob.core.windows.net/naip/v002/hi/2021/hi_060cm_2021/20155/61/m_2015561_sw_05_060_20211226_20220909.tif\n\n\ntype: image/tiff; application=geotiff; profile=cloud-optimized\n\n\ntitle: RGBIR COG tile\n\n\nroles: ['data']\n\n\nowner: hi_m_2015561_sw_05_060_20211226_20220909\n\n\neo:bands: [{'name': 'Red', 'common_name': 'red'}, {'name': 'Green', 'common_name': 'green'}, {'name': 'Blue', 'common_name': 'blue'}, {'name': 'NIR', 'common_name': 'nir', 'description': 'near-infrared'}]\n\n\n\n\n\n\n\n\n\n\nAsset: Thumbnail\n\n\n\nhref: https://naipeuwest.blob.core.windows.net/naip/v002/hi/2021/hi_060cm_2021/20155/m_2015561_sw_05_060_20211226_20220909.200.jpg\n\n\ntype: image/jpeg\n\n\ntitle: Thumbnail\n\n\nroles: ['thumbnail']\n\n\nowner: hi_m_2015561_sw_05_060_20211226_20220909\n\n\n\n\n\n\n\n\n\n\nAsset: TileJSON with default rendering\n\n\n\nhref: https://planetarycomputer.microsoft.com/api/data/v1/item/tilejson.json?collection=naip&item=hi_m_2015561_sw_05_060_20211226_20220909&assets=image&asset_bidx=image%7C1%2C2%2C3&format=png\n\n\ntype: application/json\n\n\ntitle: TileJSON with default rendering\n\n\nroles: ['tiles']\n\n\nowner: hi_m_2015561_sw_05_060_20211226_20220909\n\n\n\n\n\n\n\n\n\n\nAsset: Rendered preview\n\n\n\nhref: https://planetarycomputer.microsoft.com/api/data/v1/item/preview.png?collection=naip&item=hi_m_2015561_sw_05_060_20211226_20220909&assets=image&asset_bidx=image%7C1%2C2%2C3&format=png\n\n\ntype: image/png\n\n\ntitle: Rendered preview\n\n\nroles: ['overview']\n\n\nowner: hi_m_2015561_sw_05_060_20211226_20220909\n\n\nrel: preview\n\n\n\n\n\n\n\nLinks\n\n\n\n\n\nLink:\n\n\n\nrel: collection\n\n\nhref: https://planetarycomputer.microsoft.com/api/stac/v1/collections/naip\n\n\ntype: application/json\n\n\n\n\n\n\n\n\n\n\nLink:\n\n\n\nrel: parent\n\n\nhref: https://planetarycomputer.microsoft.com/api/stac/v1/collections/naip\n\n\ntype: application/json\n\n\n\n\n\n\n\n\n\n\nLink: Microsoft Planetary Computer STAC API\n\n\n\nrel: root\n\n\nhref: https://planetarycomputer.microsoft.com/api/stac/v1/\n\n\ntype: application/json\n\n\ntitle: Microsoft Planetary Computer STAC API\n\n\n\n\n\n\n\n\n\n\nLink:\n\n\n\nrel: self\n\n\nhref: https://planetarycomputer.microsoft.com/api/stac/v1/collections/naip/items/hi_m_2015561_sw_05_060_20211226_20220909\n\n\ntype: application/geo+json\n\n\n\n\n\n\n\n\n\n\nLink: Map of item\n\n\n\nrel: preview\n\n\nhref: https://planetarycomputer.microsoft.com/api/data/v1/item/map?collection=naip&item=hi_m_2015561_sw_05_060_20211226_20220909\n\n\ntype: text/html\n\n\ntitle: Map of item\n\n\n\n\n\n\n\n\n\n\nLinks\n\n\n\n\n\nLink:\n\n\n\nrel: items\n\n\nhref: https://planetarycomputer.microsoft.com/api/stac/v1/collections/naip/items\n\n\ntype: application/geo+json\n\n\n\n\n\n\n\n\n\n\nLink: Microsoft Planetary Computer STAC API\n\n\n\nrel: root\n\n\nhref: https://planetarycomputer.microsoft.com/api/stac/v1/\n\n\ntype: application/json\n\n\ntitle: Microsoft Planetary Computer STAC API\n\n\n\n\n\n\n\n\n\n\nLink: Public Domain\n\n\n\nrel: license\n\n\nhref: https://www.fsa.usda.gov/help/policies-and-links/\n\n\ntitle: Public Domain\n\n\n\n\n\n\n\n\n\n\nLink: Human readable dataset overview and reference\n\n\n\nrel: describedby\n\n\nhref: https://planetarycomputer.microsoft.com/dataset/naip\n\n\ntype: text/html\n\n\ntitle: Human readable dataset overview and reference\n\n\n\n\n\n\n\n\n\n\nLink:\n\n\n\nrel: self\n\n\nhref: https://planetarycomputer.microsoft.com/api/stac/v1/collections/naip\n\n\ntype: application/json\n\n\n\n\n\n\n\n\n\n\nLink: Microsoft Planetary Computer STAC API\n\n\n\nrel: parent\n\n\nhref: https://planetarycomputer.microsoft.com/api/stac/v1\n\n\ntype: application/json\n\n\ntitle: Microsoft Planetary Computer STAC API\n\n\n\n\n\n\n\nAssets\n\n\n\n\n\nAsset: NAIP thumbnail\n\n\n\nhref: https://ai4edatasetspublicassets.blob.core.windows.net/assets/pc_thumbnails/naip.png\n\n\ntype: image/png\n\n\ntitle: NAIP thumbnail\n\n\nroles: ['thumbnail']\n\n\nowner: naip\n\n\n\n\n\n\n\n\n\n\nAsset: GeoParquet STAC items\n\n\n\nhref: abfs://items/naip.parquet\n\n\ntype: application/x-parquet\n\n\ntitle: GeoParquet STAC items\n\n\ndescription: Snapshot of the collection's STAC items exported to GeoParquet format.\n\n\nroles: ['stac-items']\n\n\nowner: naip\n\n\nmsft:partition_info: {'is_partitioned': True, 'partition_frequency': 'AS'}\n\n\ntable:storage_options: {'account_name': 'pcstacitems'}"
  },
  {
    "objectID": "blog/2023-12-11-aiclimate/index.html",
    "href": "blog/2023-12-11-aiclimate/index.html",
    "title": "Ethics and Bias in Environmental Data Science",
    "section": "",
    "text": "“Humanizing science, policy, and practice can create spaces that value and integrate diverse knowledge systems, foster meaningful engagement with affected communities, and promote inclusive decision-making processes. This approach recognizes the limitations of AI and emphasizes the critical role of human judgment, empathy, and ethical considerations in ensuring responsible and equitable outcomes in addressing climate change and other societal challenges” (Chamuah, Ale, Mathur, 2012)."
  },
  {
    "objectID": "blog/2023-12-11-aiclimate/index.html#introduction",
    "href": "blog/2023-12-11-aiclimate/index.html#introduction",
    "title": "Ethics and Bias in Environmental Data Science",
    "section": "Introduction",
    "text": "Introduction\nThe goal of this blog post is to explore the use of artificial intelligence (AI) in climate change solutions and its limitations through the lens of ethics and bias. I introduce the topic with an example of how AI is being used for problem solving climate change at the individual level (i.e., reduction in energy consumption at data centers), where related impacts are direct and mostly limited to the site itself. Next, I explore the use of AI at larger community and regional scales for climate resiliency and adaptation policies and urge scientists and practitioners to consider potential indirect risks when building scalable solutions. To conclude, I suggest emphasizing a human-centered approach when using AI to develop climate change solutions."
  },
  {
    "objectID": "blog/2023-12-11-aiclimate/index.html#ai-and-problem-solving-at-individual-scale",
    "href": "blog/2023-12-11-aiclimate/index.html#ai-and-problem-solving-at-individual-scale",
    "title": "Ethics and Bias in Environmental Data Science",
    "section": "AI and Problem Solving at Individual Scale",
    "text": "AI and Problem Solving at Individual Scale\nAI can be alluring in its promise to revolutionize how we tackle pressing and complex environmental problems. By processing and learning from large amounts of data, AI could generate intelligent predictions to mitigate future risks and uncertainties related to climate change. Similar solutions would otherwise take human minds more time, effort, and resources to produce. Thus, the application of AI can increase our abilities to solve environmental problems faster. Let’s look at how AI is being used to reduce energy consumption at Google’s data centers.\nAt an individual scale where AI is applied to either one or a limited number of sites, AI could provide efficient solutions to physical environmental problems. According to the International Energy Agency, data centers worldwide consume upwards of 250 terawatt-hours (TWh) of electricity, representing around one percent of global electricity demand and 0.3 percent of global carbon emissions. That number is expected to reach eight percent by 2030 (Tahah 2023). Google’s DeepMind team has been working on building general AI systems for various applications and has recently been used to reduce energy consumption of data centers. In 2015, DeepMind received media attention for its success with AlphaGo, the first computer program to defeat a Go world champion. This was a landmark achievement as Go was more difficult for computers to win compared to other games like chess, due to the larger number of possible moves. Since then, DeepMind’s machine learning has been used to reduce energy consumption at Google’s own data centers by 40 percent. This was accomplished by taking historical data such as temperatures, power, pump speeds, setpoints, etc. and using it to train an ensemble of deep neural networks to predict future temperatures and optimize efficiency. Possible future applications of this technology include improving power plant conversion efficiency (getting more energy from the same unit of input), reducing semiconductor manufacturing energy and water usage, or helping manufacturing facilities increase throughput (DeepMind 2016).\nI argue that DeepMind’s contribution towards a reduction in energy consumption at Google’s data center is a positive use of AI. While applying AI to data centers can have potential indirect impacts on communities (GHG, land use, noise, visual impacts), I believe that these indirect impacts are limited when compared to other cases where AI has been applied to create large-scaled social solutions."
  },
  {
    "objectID": "blog/2023-12-11-aiclimate/index.html#ai-and-climate-adaptation",
    "href": "blog/2023-12-11-aiclimate/index.html#ai-and-climate-adaptation",
    "title": "Ethics and Bias in Environmental Data Science",
    "section": "AI and Climate Adaptation",
    "text": "AI and Climate Adaptation\nEfforts have sped up in terms of exploring the use of AI in climate change solutions. Recently, the United Nations Framework Convention on Climate Change (UNFCCC) Technology Mechanism launched a five-year work plan (2023-27) to explore the role of “AI as a powerful technological tool…in advancing and scaling up transformative climate solutions, particularly for the most vulnerable communities” (UNFCCC 2023). Within climate change adaptation, AI is used in cities and mobility sustainability; housing cooling system; water sustainability; energy sustainability. Figure 1 shows that 38% of studies pertinent to water-related issues under climate change, including flood prediction and irrigation management, have attracted the most research attention on examining the application of AI for adaptation (Filho et al., 2022). Table 1 shows a comparison of AI-powered vulnerability assessment tools for climate change adaptation (Jain, 2023).\nFig. 1. Distribution of main research areas on AI application by the identified research publications\n\n\nHowever, when scaled up to the community and regional levels, AI solutions to climate change can have broader implications on historically marginalized and vulnerable populations. When developing climate adaptation solutions using AI, we should consider whether these solutions are appropriate for the community being evaluated and ask whether there would be increased risk of secondary harm. For example, following lethal landslides in Rio de Janeiro in 2010, urban risk mapping and management projects (Mendes Barbosa and Walker 2020) disproportionately led to the clearance of favelas (slums) in Brazil. Displacement of these favela populations resulted in instant backlash as the evictions were seen as pretext for forcefully removing poor residents from valuable property. This case study serves as an important reminder to examine who holds power and who is creating the narrative when implementing scientifically informed policies and projects during critical decision-making processes."
  },
  {
    "objectID": "blog/2023-12-11-aiclimate/index.html#human-centered-approach",
    "href": "blog/2023-12-11-aiclimate/index.html#human-centered-approach",
    "title": "Ethics and Bias in Environmental Data Science",
    "section": "Human-centered Approach",
    "text": "Human-centered Approach\nClimate change is a multifaceted issue with social, economic and environmental implications. I urge that scientists and practitioners consider a human-centered approach where diverse perspectives and people’s lived experiences are included early and often in the decision-making process. While the use of AI is promising in its ability to generate solutions to environmental problems, we must be cautious that existing injustices are not further intensified. By ensuring the well-being of all individuals, not just a select group of decision-makers, we can ensure that we implement technology in ways that are meaningful and empathically."
  },
  {
    "objectID": "blog/2023-12-11-aiclimate/index.html#references",
    "href": "blog/2023-12-11-aiclimate/index.html#references",
    "title": "Ethics and Bias in Environmental Data Science",
    "section": "References",
    "text": "References\nChamuah, Angelina, Ale, Hema Vaishnavi, Mathur, Vikrom. AI, Climate Adaptation, and Epistemic Injustice. CASTAC blog, July 20, 2023. https://blog.castac.org/2023/07/ai-climate-adaptation-and-epistemic-injustice/\nEvans, Richard, Gao, Jim. DeepMind AI Reduces Google Data Centre Cooling Bill by 40%. Google DeepMind, July 20, 2016. https://deepmind.google/discover/blog/deepmind-ai-reduces-google-data-centre-cooling-bill-by-40/\nTaha, Nabil. The path to data center decarbonization starts now. Data Center Dynamics, July 28, 2023.  https://www.datacenterdynamics.com/en/opinions/the-path-to-data-center-decarbonization-starts-now/#:~:text=According%20to%20the%20International%20Energy,reach%20eight%20percent%20by%202030.\nPhillips, Tom. Rio slum dwellers face forced eviction after landslides. The Guardian, April 11, 2010. https://www.theguardian.com/world/2010/apr/11/rio-brazil-slum-forced-evictions\nFilho, Walter Leal, Wall, Tony, Afonso Rui Mucova, Serafino, J. Nagy, Gustavo, Balogun, Abdul-Lateef, M. Luetz, Johannes, W. Ng, Artie, Kovaleva, Marina, Mohammad Safiul Azam, Fardous, Alves, Fátima, Guevara, Zeus, R Matandirotya, Newton, Skouloudis, Antonis, Tzachor, Asaf, Malakar, Krishna, Gandhi, Odhiambo. Deploying artificial intelligence for climate change adaptation. Technological Forecasting and Social Change, Volume 180, 2022. https://doi.org/10.1016/j.techfore.2022.121662.\nJain, H., Dhupper, R., Shrivastava, A. et al. AI-enabled strategies for climate change adaptation: protecting communities, infrastructure, and businesses from the impacts of climate change. Comput.Urban Sci. 3, 25 (2023). https://doi.org/10.1007/s43762-023-00100-2\nMendes Barbosa, Luciana, Walker, Gordon. Copernicus Publications, November 12, 2020. Epistemic injustice, risk mapping and climatic events: analysing epistemic resistance in the context of favela removal in Rio de Janeiro. https://doi.org/10.5194/gh-75-381-2020\nYay"
  },
  {
    "objectID": "blog/2023-12-12-poverty-climate-readiness/climateadapt.html",
    "href": "blog/2023-12-12-poverty-climate-readiness/climateadapt.html",
    "title": "Impact of Poverty on a City’s Overall Readiness for Climate Adaptation",
    "section": "",
    "text": "This blog post will explore analysis conducted on whether poverty impacts a city’s overall readiness to implement climate adaptation measures at both national and regional levels in the United States.\n\n\nWhat impact does the percentage of population in poverty have on a city’s overall readiness score for climate adaptation?\n\n\nClimate change is upon us. The task of addressing its intensifying effects is daunting and more urgent than ever. We need to adapt to climate change now, which means taking action to adjust to its present and future impacts (EU 2023).\nAdaptation and resilience refers to adjustments in ecological, social or economic systems in response to actual or expected climatic stimuli and their effects. At the global stage, we have seen governments iterate the importance of climate adaptation and resilience. Adopted in 2015 and signed in 2016, the Paris Agreement is a legally binding international treaty on climate change. All Parties to the Paris Agreement committed to strengthening the global response to climate change by increasing the ability of all to adapt and build resilience, and reduce vulnerability. In order to do so, governments will need access to clear and accurate data as they move to prepare our economies and communities as a whole. It is important to consider the effects of adaptation on less resourced communities, as poor populations tend to be the most vulnerable to climate change and least able to adapt because of limited capacity to cope with climate variability and extremes. For example, many socially vulnerable groups (i.e., low-income households, communities of color, the unhoused, and immigrant populations) live in urban areas that are prone to extreme heat (urban heat islands). Some may also live in housing that does have adequate insulation or cooling. Others may not be able to afford air conditioning. It should be noted that this is just one aspect of social vulnerability and overlaps may occur.\nThis analysis will provide exploratory analysis on whether poverty is a factor in how ready a city is for climate change. A total of 278 cities within the United States, including 50 states and Puerto Rico, whose populations are above 100,000 people will be examined.\n\n\n\nClimate adaptation readiness (hereon referred to as ‘climate readiness’) and poverty data used for this analysis is publicly available from the Notre Dame Global Adaptation Initiative through its Urban Adaptation Assessment. The data is available in CSV format, with nine independent files that reflect data used to generate each of the hazard scores and forecasts and the primary data at the city level and sub-city level (census tract). Each file has a common city, state and geographic identifiers (GEOIDs) variable that permits easy identification and merging, if necessary. The City Indicators.csv and Overall Risk & Readiness Scores.csv files were both used for the analysis.\n\n\n\n\nI started with basic analysis to explore the data. Luckily, the two data files have common geospatial and temporal features that allowed for easy manipulation and use. Minor cleaning was required to correct inaccurate spelling and to ensure uniform formatting in column names. Once I checked that both data files had matching cities and number of observations, I combined the datasets based on city names to create a merged dataframe which includes percentage of population in poverty and overall climate adaptation readiness. I also removed certain columns to make the merged dataframe easier to work with.\nNext, I chose to conduct a simple linear regression model as the two variables I am studying are numeric values. I used ‘ggplot’ to create a scatter plot comparing the percent of population in poverty to the climate readiness score for each city. Then I used ‘geom_smooth()’ to plot the linear regression between poverty and climate readiness. As a basic gut check, the line shows that there is a negative correlation between the two variables, which makes sense as higher poverty would decrease ability to implement costly climate adaptation measures.\nI also conducted a two-tailed t-test to see whether there was a difference in the impact of poverty on climate readiness between two regions (West and South).\n\nknitr::opts_chunk$set(echo = TRUE)\n\n# load all the packages needed \nlibrary(tidyverse)\nlibrary(readr)\nlibrary(gt)\nlibrary(tufte)\nlibrary(sf)\nlibrary(feasts)\nlibrary(dplyr)\nlibrary(janitor)\nlibrary(ggplot2)\n\n# set the filepath  \nrootdir &lt;- (\"/Users/lianechen/Documents/MEDS_2023/Fall_2023/EDS222/Final/eds222-climateadapt\")\n\ndatadir &lt;- file.path(rootdir,\"data\")\n\n# import data\ncity_indicators &lt;- read.csv(\"data/City Indicators.csv\")\nreadiness &lt;- read.csv(\"data/Overall Risk & Readiness Scores.csv\")\n\n\n# clean column names for both datasets\ncity_indicators &lt;- clean_names(city_indicators)\nreadiness &lt;- clean_names(readiness)\n\n# check number of observations for city_indicators file\nnrow(city_indicators)\n\n[1] 278\n\n# check number of observations for readiness file\nnrow(readiness)\n\n[1] 278\n\n# merge city_indicators and readiness files by city name\nmerged &lt;- merge(city_indicators, readiness, by = \"city\", all = TRUE)\n\n# check that number of obersvations is consistent\nnrow(merged)\n\n[1] 278\n\n# clean column names\ncolnames(merged)[colnames(merged) == \"geo_id.x\"] &lt;- \"geo_id\"\ncolnames(merged)[colnames(merged) == \"state.x\"] &lt;- \"state\"\ncolnames(merged)[colnames(merged) == \"latitutde\"] &lt;- \"latitude\"\n\n# streamline the columns so only relevant ones are kept\nincome_readiness &lt;- merged[, c(\"city\", \"state\", \"geo_id\", \"percent_of_population_spending_over_50_percent_of_income_on_rent_2015\", \"percent_of_population_in_poverty_2015\", \"latitude\", \"longitude\", \"county\", \"region\", \"median_income\", \"overall_readiness\")]\n\n\n# create scatter plot with simple regression line included\nggplot(data=income_readiness, aes(x=percent_of_population_in_poverty_2015, y = overall_readiness)) + \n  geom_point(alpha=0.1, size=3) + \n  geom_smooth(method='lm', formula= y~x, color=\"lightcoral\", se=F, linewidth=1.5) +\n  theme_bw() +\n  labs(title = \"Scatterplot of % in Poverty vs Overall Readiness with Regression Line\",\n       x = \"Percent of population in poverty (2015)\", y = \"Overall readiness\")\n\n\n\n\nThe slope of the regression line shows to be slightly negative, as y decreases while x increases. This seems to make intuitive sense, as increased poverty could relate to decreased ability to adapt to climate variability and extremes.\nThe slope is not too steep, so let’s take a look at correlation to see how strongly poverty impacts climate adaptation readiness.\n\n# compute the correlation coefficient to quantify the strength and direction of the relationship between poverty and climate readiness\n\ncor(income_readiness$percent_of_population_in_poverty_2015, income_readiness$overall_readiness)\n\n[1] -0.1565957\n\n\nMagnitude of the Correlation Coefficient:\nThe correlation coefficient ranges from -1 to 1. A value of -1 indicates a perfect negative correlation, 0 indicates no correlation, and 1 indicates a perfect positive correlation.\nIn this case, the value is very close to 0, which suggests a weak correlation.\nSign of the Correlation Coefficient:\nThe negative sign indicates a negative correlation. A negative correlation means that as one variable (percentage in poverty) increases, the other variable (overall adaptation readiness) tends to decrease.\nThis matches the slight negative slope of the regression line.\nInterpretation:\nWith a correlation coefficient of -0.1565957, there is a slight tendency that areas with a higher percentage of people in poverty may have lower overall adaptation readiness. However, the correlation is weak, suggesting that other factors not considered in this analysis may play a more significant role in determining overall adaptation readiness.\n\n# linear regression model\nlinear_regression &lt;- lm(overall_readiness ~ percent_of_population_in_poverty_2015, data = income_readiness)\n\n# summary of the model\nsummary(linear_regression)\n\n\nCall:\nlm(formula = overall_readiness ~ percent_of_population_in_poverty_2015, \n    data = income_readiness)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-0.30807 -0.08339 -0.00655  0.07662  0.35538 \n\nCoefficients:\n                                        Estimate Std. Error t value Pr(&gt;|t|)\n(Intercept)                            0.5098146  0.0163942  31.097  &lt; 2e-16\npercent_of_population_in_poverty_2015 -0.0023953  0.0009093  -2.634  0.00891\n                                         \n(Intercept)                           ***\npercent_of_population_in_poverty_2015 ** \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.124 on 276 degrees of freedom\nMultiple R-squared:  0.02452,   Adjusted R-squared:  0.02099 \nF-statistic: 6.938 on 1 and 276 DF,  p-value: 0.008913\n\n\nIntercept (0.5098146):\nThe intercept represents the estimated value of the dependent variable when all independent variables are zero.\nIn this context, when the percentage of the population in poverty is zero, the estimated value of overall adaptation readiness is approximately 0.5098.\n\n# let's look at coefficients\nsummary(linear_regression)$coefficients\n\n                                          Estimate   Std. Error   t value\n(Intercept)                            0.509814590 0.0163942390 31.097179\npercent_of_population_in_poverty_2015 -0.002395259 0.0009093408 -2.634061\n                                          Pr(&gt;|t|)\n(Intercept)                           3.482886e-92\npercent_of_population_in_poverty_2015 8.913263e-03\n\n\nPercentage of Population in Poverty Coefficient (-0.0023953):\nThe coefficient for the variable “percent_of_population_in_poverty_2015” represents the estimated change in the dependent variable (overall adaptation readiness) for a one-unit change (one-percent) in the independent variable (percentage of population in poverty).\nIn this case, for every one-unit increase in the percentage of the population in poverty, the overall adaptation readiness is estimated to decrease by approximately 0.0024.\nThe t-value of -2.634 indicates that this coefficient is statistically significant (p = 0.00891), suggesting that the percentage of the population in poverty has a significant effect on overall adaptation readiness.\nIn summary, the model suggests that both the intercept and the percentage of the population in poverty are statistically significant in predicting overall adaptation readiness.\n\n\n\nI am curious whether there is a difference between how poverty impacts climate readiness in different regions of the country. Let’s conduct a two-tailed t-test.\n\n# compute point estimate\npt_est_poverty_west = income_readiness %&gt;% \n  filter(region == \"West\") %&gt;% \n  summarize(mean(percent_of_population_in_poverty_2015))\n\npt_est_poverty_south = income_readiness %&gt;% \n  filter(region == \"South\") %&gt;% \n  summarize(mean(percent_of_population_in_poverty_2015))\n\npoint_est = as.numeric(pt_est_poverty_west - pt_est_poverty_south)\nprint(point_est) \n\n[1] -3.538473\n\n\n\n# compute standard error\nn1 = income_readiness %&gt;% filter(region == \"West\") %&gt;% count()\nn2 = income_readiness %&gt;% filter(region == \"South\") %&gt;% count()\ns1 = income_readiness %&gt;% filter(region == \"West\") %&gt;% summarize(sd(percent_of_population_in_poverty_2015, na.rm = TRUE))\ns2 = income_readiness %&gt;% filter(region == \"South\") %&gt;% summarize(sd(percent_of_population_in_poverty_2015, na.rm = TRUE))\n\nSE = as.numeric(sqrt(s1^2/n1 + s2^2/n2))\nprint(SE)\n\n[1] 1.18189\n\n\n\n# compute test statistic\nzscore = (point_est - 0)/SE\nprint(zscore)\n\n[1] -2.99391\n\n\n\n#construct two-tailed t-test\ntwo_tailed &lt;- t.test(income_readiness$overall_readiness[income_readiness$region==\"West\"], income_readiness$overall_readiness[income_readiness$region==\"South\"])\n\n#print\ntwo_tailed\n\n\n    Welch Two Sample t-test\n\ndata:  income_readiness$overall_readiness[income_readiness$region == \"West\"] and income_readiness$overall_readiness[income_readiness$region == \"South\"]\nt = -2.4308, df = 92.995, p-value = 0.01698\nalternative hypothesis: true difference in means is not equal to 0\n95 percent confidence interval:\n -0.11160120 -0.01124421\nsample estimates:\nmean of x mean of y \n0.3952240 0.4566467 \n\n\nInterpreting P-value and Hypothesis Testing for Different Regions (West and South) p-value: 0.01698\nNull: The mean score for overall climate readiness in the West region is equal to the mean score for overall climate readiness in the South region when considering the impact of poverty (no difference). H_0: u_WestReadiness - u_SouthReadiness = 0\nAlternative: The mean score for overall climate readiness in the West region is NOT equal to the mean score for overall climate readiness in the South region when considering the impact of poverty (yes, there is a difference). H_A: u_WestReadiness - u_SouthReadiness != 0\nGiven that the p-value is less than the significance level of ‘alpha=0.05’, we reject the null hypothesis. Therefore, we can say that there is a difference in mean overall climate readiness between the West and the South when considering the impact of poverty.\n\n\n\nWe are able to reject the null hypothesis and conclude that the percentage of people living in poverty does indeed have an impact on a city’s climate readiness score. It should be noted that while there is a correlation, it is relatively weak, which suggests that further analysis should be completed.\n\n\n\nCorrelation does not imply causation. Even though we found above that there is a correlation, it doesn’t necessarily mean that poverty causes lower adaptation readiness or vice versa. Other factors might contribute to the observed relationship. Future work should explore additional variables and regression analysis to better understand the specific nature and strength of the relationship, with controls included. Further assess the statistical significance of the correlation coefficient to determine whether the observed relationship is likely due to chance.\nIn summary, the negative correlation coefficient suggests a weak tendency for areas with a higher percentage of people in poverty to have lower overall adaptation readiness. The strength of this relationship is not strong, and it’s important to interpret such correlations cautiously, considering other factors that might influence the observed pattern. Potential areas for further work are described below.\n\n\nThe datasets used included 278 cities within the United States, including 50 states and Puerto Rico, whose populations are above 100,000 people. However, increased data for cities with population under 100,000 would provide a broader understanding of potential opportunity areas for climate adaptation.\n\n\n\nThis analysis would benefit from additional years of data for percentage of populations living in poverty from the Census. While these numbers would likely not vary too dramatically between years, it would provide more accurate data.\n\n\n\nWe have available data for percentage of populations living in poverty, but what about wealthy populations? It would be helpful (and interesting!) to be able to statistically compare whether wealth has an impact on climate readiness.\n\n\n\n\nhttps://github.com/lchenhub/eds222-climate-adaptation.git\n\n\n\n\n\n\nUniversity of Notre Dame, Global Adaptation Initiative: https://gain-uaa.nd.edu/\n\n\n\n\n\nEuropean Union(EU) 2003. European Commission, Adaptation to climate change. https://climate.ec.europa.eu/eu-action/adaptation-climate-change_en\nUnited Nations 2023a. Climate Adaptation. https://www.un.org/en/climatechange/climate-adaptation\nUnited Nations 2023b. New elements and dimensions of adaptation under the Paris Agreement (Article 7). https://unfccc.int/topics/adaptation-and-resilience/the-big-picture/new-elements-and-dimensions-of-adaptation-under-the-paris-agreement-article-7\nUnited Stated Environmental Protection Agency 2023. Climate Change and the Health of Socially Vulnerable People. Last updated October 16, 2023. https://www.epa.gov/climateimpacts/climate-change-and-health-socially-vulnerable-people#:~:text=Increases%20in%20average%20and%20extreme,including%20certain%20socially%20vulnerable%20groups.&text=These%20include%20low%2Dincome%20households,experiencing%20homelessness%2C%20and%20immigrant%20populations"
  },
  {
    "objectID": "blog/2023-12-12-poverty-climate-readiness/climateadapt.html#research-question",
    "href": "blog/2023-12-12-poverty-climate-readiness/climateadapt.html#research-question",
    "title": "Impact of Poverty on a City’s Overall Readiness for Climate Adaptation",
    "section": "",
    "text": "What impact does the percentage of population in poverty have on a city’s overall readiness score for climate adaptation?\n\n\nClimate change is upon us. The task of addressing its intensifying effects is daunting and more urgent than ever. We need to adapt to climate change now, which means taking action to adjust to its present and future impacts (EU 2023).\nAdaptation and resilience refers to adjustments in ecological, social or economic systems in response to actual or expected climatic stimuli and their effects. At the global stage, we have seen governments iterate the importance of climate adaptation and resilience. Adopted in 2015 and signed in 2016, the Paris Agreement is a legally binding international treaty on climate change. All Parties to the Paris Agreement committed to strengthening the global response to climate change by increasing the ability of all to adapt and build resilience, and reduce vulnerability. In order to do so, governments will need access to clear and accurate data as they move to prepare our economies and communities as a whole. It is important to consider the effects of adaptation on less resourced communities, as poor populations tend to be the most vulnerable to climate change and least able to adapt because of limited capacity to cope with climate variability and extremes. For example, many socially vulnerable groups (i.e., low-income households, communities of color, the unhoused, and immigrant populations) live in urban areas that are prone to extreme heat (urban heat islands). Some may also live in housing that does have adequate insulation or cooling. Others may not be able to afford air conditioning. It should be noted that this is just one aspect of social vulnerability and overlaps may occur.\nThis analysis will provide exploratory analysis on whether poverty is a factor in how ready a city is for climate change. A total of 278 cities within the United States, including 50 states and Puerto Rico, whose populations are above 100,000 people will be examined.\n\n\n\nClimate adaptation readiness (hereon referred to as ‘climate readiness’) and poverty data used for this analysis is publicly available from the Notre Dame Global Adaptation Initiative through its Urban Adaptation Assessment. The data is available in CSV format, with nine independent files that reflect data used to generate each of the hazard scores and forecasts and the primary data at the city level and sub-city level (census tract). Each file has a common city, state and geographic identifiers (GEOIDs) variable that permits easy identification and merging, if necessary. The City Indicators.csv and Overall Risk & Readiness Scores.csv files were both used for the analysis."
  },
  {
    "objectID": "blog/2023-12-12-poverty-climate-readiness/climateadapt.html#data-analysis",
    "href": "blog/2023-12-12-poverty-climate-readiness/climateadapt.html#data-analysis",
    "title": "Impact of Poverty on a City’s Overall Readiness for Climate Adaptation",
    "section": "",
    "text": "I started with basic analysis to explore the data. Luckily, the two data files have common geospatial and temporal features that allowed for easy manipulation and use. Minor cleaning was required to correct inaccurate spelling and to ensure uniform formatting in column names. Once I checked that both data files had matching cities and number of observations, I combined the datasets based on city names to create a merged dataframe which includes percentage of population in poverty and overall climate adaptation readiness. I also removed certain columns to make the merged dataframe easier to work with.\nNext, I chose to conduct a simple linear regression model as the two variables I am studying are numeric values. I used ‘ggplot’ to create a scatter plot comparing the percent of population in poverty to the climate readiness score for each city. Then I used ‘geom_smooth()’ to plot the linear regression between poverty and climate readiness. As a basic gut check, the line shows that there is a negative correlation between the two variables, which makes sense as higher poverty would decrease ability to implement costly climate adaptation measures.\nI also conducted a two-tailed t-test to see whether there was a difference in the impact of poverty on climate readiness between two regions (West and South).\n\nknitr::opts_chunk$set(echo = TRUE)\n\n# load all the packages needed \nlibrary(tidyverse)\nlibrary(readr)\nlibrary(gt)\nlibrary(tufte)\nlibrary(sf)\nlibrary(feasts)\nlibrary(dplyr)\nlibrary(janitor)\nlibrary(ggplot2)\n\n# set the filepath  \nrootdir &lt;- (\"/Users/lianechen/Documents/MEDS_2023/Fall_2023/EDS222/Final/eds222-climateadapt\")\n\ndatadir &lt;- file.path(rootdir,\"data\")\n\n# import data\ncity_indicators &lt;- read.csv(\"data/City Indicators.csv\")\nreadiness &lt;- read.csv(\"data/Overall Risk & Readiness Scores.csv\")\n\n\n# clean column names for both datasets\ncity_indicators &lt;- clean_names(city_indicators)\nreadiness &lt;- clean_names(readiness)\n\n# check number of observations for city_indicators file\nnrow(city_indicators)\n\n[1] 278\n\n# check number of observations for readiness file\nnrow(readiness)\n\n[1] 278\n\n# merge city_indicators and readiness files by city name\nmerged &lt;- merge(city_indicators, readiness, by = \"city\", all = TRUE)\n\n# check that number of obersvations is consistent\nnrow(merged)\n\n[1] 278\n\n# clean column names\ncolnames(merged)[colnames(merged) == \"geo_id.x\"] &lt;- \"geo_id\"\ncolnames(merged)[colnames(merged) == \"state.x\"] &lt;- \"state\"\ncolnames(merged)[colnames(merged) == \"latitutde\"] &lt;- \"latitude\"\n\n# streamline the columns so only relevant ones are kept\nincome_readiness &lt;- merged[, c(\"city\", \"state\", \"geo_id\", \"percent_of_population_spending_over_50_percent_of_income_on_rent_2015\", \"percent_of_population_in_poverty_2015\", \"latitude\", \"longitude\", \"county\", \"region\", \"median_income\", \"overall_readiness\")]\n\n\n# create scatter plot with simple regression line included\nggplot(data=income_readiness, aes(x=percent_of_population_in_poverty_2015, y = overall_readiness)) + \n  geom_point(alpha=0.1, size=3) + \n  geom_smooth(method='lm', formula= y~x, color=\"lightcoral\", se=F, linewidth=1.5) +\n  theme_bw() +\n  labs(title = \"Scatterplot of % in Poverty vs Overall Readiness with Regression Line\",\n       x = \"Percent of population in poverty (2015)\", y = \"Overall readiness\")\n\n\n\n\nThe slope of the regression line shows to be slightly negative, as y decreases while x increases. This seems to make intuitive sense, as increased poverty could relate to decreased ability to adapt to climate variability and extremes.\nThe slope is not too steep, so let’s take a look at correlation to see how strongly poverty impacts climate adaptation readiness.\n\n# compute the correlation coefficient to quantify the strength and direction of the relationship between poverty and climate readiness\n\ncor(income_readiness$percent_of_population_in_poverty_2015, income_readiness$overall_readiness)\n\n[1] -0.1565957\n\n\nMagnitude of the Correlation Coefficient:\nThe correlation coefficient ranges from -1 to 1. A value of -1 indicates a perfect negative correlation, 0 indicates no correlation, and 1 indicates a perfect positive correlation.\nIn this case, the value is very close to 0, which suggests a weak correlation.\nSign of the Correlation Coefficient:\nThe negative sign indicates a negative correlation. A negative correlation means that as one variable (percentage in poverty) increases, the other variable (overall adaptation readiness) tends to decrease.\nThis matches the slight negative slope of the regression line.\nInterpretation:\nWith a correlation coefficient of -0.1565957, there is a slight tendency that areas with a higher percentage of people in poverty may have lower overall adaptation readiness. However, the correlation is weak, suggesting that other factors not considered in this analysis may play a more significant role in determining overall adaptation readiness.\n\n# linear regression model\nlinear_regression &lt;- lm(overall_readiness ~ percent_of_population_in_poverty_2015, data = income_readiness)\n\n# summary of the model\nsummary(linear_regression)\n\n\nCall:\nlm(formula = overall_readiness ~ percent_of_population_in_poverty_2015, \n    data = income_readiness)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-0.30807 -0.08339 -0.00655  0.07662  0.35538 \n\nCoefficients:\n                                        Estimate Std. Error t value Pr(&gt;|t|)\n(Intercept)                            0.5098146  0.0163942  31.097  &lt; 2e-16\npercent_of_population_in_poverty_2015 -0.0023953  0.0009093  -2.634  0.00891\n                                         \n(Intercept)                           ***\npercent_of_population_in_poverty_2015 ** \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.124 on 276 degrees of freedom\nMultiple R-squared:  0.02452,   Adjusted R-squared:  0.02099 \nF-statistic: 6.938 on 1 and 276 DF,  p-value: 0.008913\n\n\nIntercept (0.5098146):\nThe intercept represents the estimated value of the dependent variable when all independent variables are zero.\nIn this context, when the percentage of the population in poverty is zero, the estimated value of overall adaptation readiness is approximately 0.5098.\n\n# let's look at coefficients\nsummary(linear_regression)$coefficients\n\n                                          Estimate   Std. Error   t value\n(Intercept)                            0.509814590 0.0163942390 31.097179\npercent_of_population_in_poverty_2015 -0.002395259 0.0009093408 -2.634061\n                                          Pr(&gt;|t|)\n(Intercept)                           3.482886e-92\npercent_of_population_in_poverty_2015 8.913263e-03\n\n\nPercentage of Population in Poverty Coefficient (-0.0023953):\nThe coefficient for the variable “percent_of_population_in_poverty_2015” represents the estimated change in the dependent variable (overall adaptation readiness) for a one-unit change (one-percent) in the independent variable (percentage of population in poverty).\nIn this case, for every one-unit increase in the percentage of the population in poverty, the overall adaptation readiness is estimated to decrease by approximately 0.0024.\nThe t-value of -2.634 indicates that this coefficient is statistically significant (p = 0.00891), suggesting that the percentage of the population in poverty has a significant effect on overall adaptation readiness.\nIn summary, the model suggests that both the intercept and the percentage of the population in poverty are statistically significant in predicting overall adaptation readiness."
  },
  {
    "objectID": "blog/2023-12-12-poverty-climate-readiness/climateadapt.html#two-tailed-t-testing",
    "href": "blog/2023-12-12-poverty-climate-readiness/climateadapt.html#two-tailed-t-testing",
    "title": "Impact of Poverty on a City’s Overall Readiness for Climate Adaptation",
    "section": "",
    "text": "I am curious whether there is a difference between how poverty impacts climate readiness in different regions of the country. Let’s conduct a two-tailed t-test.\n\n# compute point estimate\npt_est_poverty_west = income_readiness %&gt;% \n  filter(region == \"West\") %&gt;% \n  summarize(mean(percent_of_population_in_poverty_2015))\n\npt_est_poverty_south = income_readiness %&gt;% \n  filter(region == \"South\") %&gt;% \n  summarize(mean(percent_of_population_in_poverty_2015))\n\npoint_est = as.numeric(pt_est_poverty_west - pt_est_poverty_south)\nprint(point_est) \n\n[1] -3.538473\n\n\n\n# compute standard error\nn1 = income_readiness %&gt;% filter(region == \"West\") %&gt;% count()\nn2 = income_readiness %&gt;% filter(region == \"South\") %&gt;% count()\ns1 = income_readiness %&gt;% filter(region == \"West\") %&gt;% summarize(sd(percent_of_population_in_poverty_2015, na.rm = TRUE))\ns2 = income_readiness %&gt;% filter(region == \"South\") %&gt;% summarize(sd(percent_of_population_in_poverty_2015, na.rm = TRUE))\n\nSE = as.numeric(sqrt(s1^2/n1 + s2^2/n2))\nprint(SE)\n\n[1] 1.18189\n\n\n\n# compute test statistic\nzscore = (point_est - 0)/SE\nprint(zscore)\n\n[1] -2.99391\n\n\n\n#construct two-tailed t-test\ntwo_tailed &lt;- t.test(income_readiness$overall_readiness[income_readiness$region==\"West\"], income_readiness$overall_readiness[income_readiness$region==\"South\"])\n\n#print\ntwo_tailed\n\n\n    Welch Two Sample t-test\n\ndata:  income_readiness$overall_readiness[income_readiness$region == \"West\"] and income_readiness$overall_readiness[income_readiness$region == \"South\"]\nt = -2.4308, df = 92.995, p-value = 0.01698\nalternative hypothesis: true difference in means is not equal to 0\n95 percent confidence interval:\n -0.11160120 -0.01124421\nsample estimates:\nmean of x mean of y \n0.3952240 0.4566467 \n\n\nInterpreting P-value and Hypothesis Testing for Different Regions (West and South) p-value: 0.01698\nNull: The mean score for overall climate readiness in the West region is equal to the mean score for overall climate readiness in the South region when considering the impact of poverty (no difference). H_0: u_WestReadiness - u_SouthReadiness = 0\nAlternative: The mean score for overall climate readiness in the West region is NOT equal to the mean score for overall climate readiness in the South region when considering the impact of poverty (yes, there is a difference). H_A: u_WestReadiness - u_SouthReadiness != 0\nGiven that the p-value is less than the significance level of ‘alpha=0.05’, we reject the null hypothesis. Therefore, we can say that there is a difference in mean overall climate readiness between the West and the South when considering the impact of poverty."
  },
  {
    "objectID": "blog/2023-12-12-poverty-climate-readiness/climateadapt.html#results",
    "href": "blog/2023-12-12-poverty-climate-readiness/climateadapt.html#results",
    "title": "Impact of Poverty on a City’s Overall Readiness for Climate Adaptation",
    "section": "",
    "text": "We are able to reject the null hypothesis and conclude that the percentage of people living in poverty does indeed have an impact on a city’s climate readiness score. It should be noted that while there is a correlation, it is relatively weak, which suggests that further analysis should be completed."
  },
  {
    "objectID": "blog/2023-12-12-poverty-climate-readiness/climateadapt.html#future-work",
    "href": "blog/2023-12-12-poverty-climate-readiness/climateadapt.html#future-work",
    "title": "Impact of Poverty on a City’s Overall Readiness for Climate Adaptation",
    "section": "",
    "text": "Correlation does not imply causation. Even though we found above that there is a correlation, it doesn’t necessarily mean that poverty causes lower adaptation readiness or vice versa. Other factors might contribute to the observed relationship. Future work should explore additional variables and regression analysis to better understand the specific nature and strength of the relationship, with controls included. Further assess the statistical significance of the correlation coefficient to determine whether the observed relationship is likely due to chance.\nIn summary, the negative correlation coefficient suggests a weak tendency for areas with a higher percentage of people in poverty to have lower overall adaptation readiness. The strength of this relationship is not strong, and it’s important to interpret such correlations cautiously, considering other factors that might influence the observed pattern. Potential areas for further work are described below.\n\n\nThe datasets used included 278 cities within the United States, including 50 states and Puerto Rico, whose populations are above 100,000 people. However, increased data for cities with population under 100,000 would provide a broader understanding of potential opportunity areas for climate adaptation.\n\n\n\nThis analysis would benefit from additional years of data for percentage of populations living in poverty from the Census. While these numbers would likely not vary too dramatically between years, it would provide more accurate data.\n\n\n\nWe have available data for percentage of populations living in poverty, but what about wealthy populations? It would be helpful (and interesting!) to be able to statistically compare whether wealth has an impact on climate readiness."
  },
  {
    "objectID": "blog/2023-12-12-poverty-climate-readiness/climateadapt.html#code-availability",
    "href": "blog/2023-12-12-poverty-climate-readiness/climateadapt.html#code-availability",
    "title": "Impact of Poverty on a City’s Overall Readiness for Climate Adaptation",
    "section": "",
    "text": "https://github.com/lchenhub/eds222-climate-adaptation.git"
  },
  {
    "objectID": "blog/2023-12-12-poverty-climate-readiness/climateadapt.html#references",
    "href": "blog/2023-12-12-poverty-climate-readiness/climateadapt.html#references",
    "title": "Impact of Poverty on a City’s Overall Readiness for Climate Adaptation",
    "section": "",
    "text": "University of Notre Dame, Global Adaptation Initiative: https://gain-uaa.nd.edu/\n\n\n\n\n\nEuropean Union(EU) 2003. European Commission, Adaptation to climate change. https://climate.ec.europa.eu/eu-action/adaptation-climate-change_en\nUnited Nations 2023a. Climate Adaptation. https://www.un.org/en/climatechange/climate-adaptation\nUnited Nations 2023b. New elements and dimensions of adaptation under the Paris Agreement (Article 7). https://unfccc.int/topics/adaptation-and-resilience/the-big-picture/new-elements-and-dimensions-of-adaptation-under-the-paris-agreement-article-7\nUnited Stated Environmental Protection Agency 2023. Climate Change and the Health of Socially Vulnerable People. Last updated October 16, 2023. https://www.epa.gov/climateimpacts/climate-change-and-health-socially-vulnerable-people#:~:text=Increases%20in%20average%20and%20extreme,including%20certain%20socially%20vulnerable%20groups.&text=These%20include%20low%2Dincome%20households,experiencing%20homelessness%2C%20and%20immigrant%20populations"
  }
]